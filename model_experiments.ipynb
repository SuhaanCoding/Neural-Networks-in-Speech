{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# CNN Activation Function Comparison\n",
    "\n",
    "This notebook compares different activation functions (Tanh, ReLU, Leaky ReLU) for speech command classification using 1D CNNs.\n",
    "\n",
    "The goal is to see how different activation functions affect model performance on audio classification tasks. I'll train the same CNN architecture with each activation and compare the results.\n",
    "\n",
    "## Dataset format\n",
    "Put your audio files in folders by class:\n",
    "```\n",
    "my_dataset/\n",
    "├── left/\n",
    "│   ├── sample1.wav\n",
    "│   ├── sample2.wav\n",
    "├── right/\n",
    "│   ├── sample1.wav\n",
    "│   ├── sample2.wav\n",
    "└── stop/\n",
    "    ├── sample1.wav\n",
    "    └── sample2.wav\n",
    "```\n",
    "\n",
    "## How to use\n",
    "1. Update the dataset path in the config section\n",
    "2. Run all cells to train models with each activation function  \n",
    "3. Check the results comparison at the end\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Imports and setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['librosa', 'pandas', 'seaborn', 'matplotlib', 'tensorflow', 'scikit-learn']\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Ready to start experiments\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this path to point to your dataset\n",
    "dataset_path = \"/Users/alex/speech_data\"  # <-- Change this to your data folder\n",
    "results_dir = \"experiment_results\"\n",
    "sample_rate = 16000\n",
    "epochs = 10\n",
    "test_size = 0.1\n",
    "\n",
    "print(\"Dataset:\", dataset_path)\n",
    "print(\"Will train for\", epochs, \"epochs\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Load and prep data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_samples_per_class(data_dir):\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(data_dir):\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            class_counts[class_name] = len(os.listdir(class_path))\n",
    "    return class_counts\n",
    "\n",
    "def load_audio_data(data_dir):\n",
    "    audio_data = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_name in os.listdir(data_dir):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "            \n",
    "        for audio_file in os.listdir(class_dir):\n",
    "            if audio_file.endswith(('.wav', '.mp3')):\n",
    "                file_path = os.path.join(class_dir, audio_file)\n",
    "                try:\n",
    "                    audio, sr = librosa.load(file_path, sr=sample_rate)\n",
    "                    audio_data.append(audio)\n",
    "                    labels.append(class_name)\n",
    "                except:\n",
    "                    print(f\"Couldn't load {file_path}\")\n",
    "                    \n",
    "    return audio_data, labels\n",
    "\n",
    "def make_label_encoder(labels):\n",
    "    unique_labels = sorted(set(labels))\n",
    "    label_to_int = {label: i for i, label in enumerate(unique_labels)}\n",
    "    encoded = [label_to_int[label] for label in labels]\n",
    "    return np.array(encoded), label_to_int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what's in the dataset\n",
    "print(\"Sample counts per class:\")\n",
    "counts = count_samples_per_class(dataset_path)\n",
    "for class_name, count in counts.items():\n",
    "    print(f\"  {class_name}: {count} files\")\n",
    "\n",
    "# Load all the audio files\n",
    "print(\"\\nLoading audio files...\")\n",
    "audio_files, labels = load_audio_data(dataset_path)\n",
    "y_encoded, label_mapping = make_label_encoder(labels)\n",
    "\n",
    "# Pad/trim audio to same length and reshape for CNN\n",
    "max_len = sample_rate  # 1 second of audio\n",
    "X = []\n",
    "for audio in audio_files:\n",
    "    if len(audio) > max_len:\n",
    "        audio = audio[:max_len]  # trim\n",
    "    else:\n",
    "        audio = np.pad(audio, (0, max_len - len(audio)))  # pad\n",
    "    X.append(audio)\n",
    "\n",
    "X = np.array(X).reshape(-1, max_len, 1)\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "print(f\"Classes: {list(label_mapping.keys())}\")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=test_size, random_state=42)\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Model training helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(activation_fn, input_shape, num_classes):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv1D(16, 13, activation=activation_fn, input_shape=input_shape),\n",
    "        keras.layers.MaxPooling1D(3),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "        keras.layers.Conv1D(32, 11, activation=activation_fn),\n",
    "        keras.layers.MaxPooling1D(3),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation=activation_fn),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(64, activation=activation_fn),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, activation_name):\n",
    "    print(f\"\\nTraining with {activation_name} activation...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        verbose=1\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Get predictions and calculate metrics\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_pred_classes)\n",
    "    precision = precision_score(y_val, y_pred_classes, average='weighted')\n",
    "    recall = recall_score(y_val, y_pred_classes, average='weighted')\n",
    "    f1 = f1_score(y_val, y_pred_classes, average='weighted')\n",
    "    \n",
    "    results = {\n",
    "        'activation': activation_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'training_time': training_time,\n",
    "        'history': history.history\n",
    "    }\n",
    "    \n",
    "    print(f\"Final accuracy: {accuracy:.3f}\")\n",
    "    print(f\"Training took {training_time:.1f} seconds\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Run experiments with different activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the different activation functions to test\n",
    "activation_functions = {\n",
    "    'tanh': 'tanh',\n",
    "    'relu': 'relu', \n",
    "    'leaky_relu': tf.nn.leaky_relu\n",
    "}\n",
    "\n",
    "input_shape = (sample_rate, 1)\n",
    "num_classes = len(label_mapping)\n",
    "\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Testing activations: {list(activation_functions.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with each activation function\n",
    "experiment_results = []\n",
    "\n",
    "for activation_name, activation_fn in activation_functions.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing {activation_name.upper()} activation\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create and train model\n",
    "    model = create_cnn_model(activation_fn, input_shape, num_classes)\n",
    "    results = train_model(model, X_train, y_train, X_test, y_test, activation_name)\n",
    "    experiment_results.append(results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All experiments finished!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Compare results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the results from different activation functions\n",
    "print(\"\\nRESULTS COMPARISON\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Activation':<12} {'Accuracy':<10} {'F1 Score':<10} {'Time':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "best_result = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for result in experiment_results:\n",
    "    activation = result['activation']\n",
    "    accuracy = result['accuracy'] \n",
    "    f1 = result['f1_score']\n",
    "    time_s = result['training_time']\n",
    "    \n",
    "    print(f\"{activation:<12} {accuracy:<10.3f} {f1:<10.3f} {time_s:<10.1f}s\")\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_result = result\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"Best: {best_result['activation']} with {best_accuracy:.3f} accuracy\")\n",
    "\n",
    "# Save results\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "with open(f'{results_dir}/experiment_results.json', 'w') as f:\n",
    "    # Remove history from results to keep file size reasonable\n",
    "    save_results = []\n",
    "    for r in experiment_results:\n",
    "        save_r = r.copy()\n",
    "        save_r.pop('history', None)  # Remove training history \n",
    "        save_results.append(save_r)\n",
    "    json.dump(save_results, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to {results_dir}/experiment_results.json\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
